"""
IoTDB ä¸“ç”¨çš„å›ºå®šTask LLMæŽ¥å£
ä¸ºApache IoTDBä¼˜åŒ–ï¼Œæä¾›ç®€åŒ–çš„API
"""

import torch
import pandas as pd
from typing import Union, Optional, Dict, Any
from pathlib import Path

from ..engine.llm_engine import LLM

class IoTDBLLM:
    """
    IoTDBä¸“ç”¨çš„LLMæŽ¥å£
    - å›ºå®štaskä¸º"generate"
    - ç®€åŒ–çš„APIè®¾è®¡
    - é’ˆå¯¹æ—¶åºé¢„æµ‹ä¼˜åŒ–
    """
    
    def __init__(self, 
                 model: Union[str, Path], 
                 cache_dir: Optional[str] = None,
                 uri: Optional[str] = None,
                 **model_params):
        """
        åˆå§‹åŒ–IoTDB LLM
        
        Args:
            model: æ¨¡åž‹æ ‡è¯†ç¬¦
            cache_dir: ç¼“å­˜ç›®å½•
            uri: æ¨¡åž‹URIï¼ˆå¯é€‰ï¼‰
            **model_params: æ¨¡åž‹å‚æ•°
        """
        # å›ºå®štaskä¸ºgenerate
        self.llm = LLM(
            model=model,
            task="generate",  # å›ºå®šä¸ºgenerate
            cache_dir=cache_dir,
            uri=uri,
            **model_params
        )
        
        self.model_info = self.llm.get_model_info()
        print(f"ðŸ›ï¸  IoTDB LLM å°±ç»ª: {self.model_info['model_name']}")
    
    def forecast(self, 
                time_series: Union[torch.Tensor, list, pd.Series],
                output_length: Optional[int] = None) -> torch.Tensor:
        """
        æ—¶åºé¢„æµ‹
        
        Args:
            time_series: è¾“å…¥æ—¶åºæ•°æ®
            output_length: è¾“å‡ºé•¿åº¦ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é¢„æµ‹ç»“æžœ
        """
        # æ•°æ®é¢„å¤„ç†
        if isinstance(time_series, (list, pd.Series)):
            time_series = torch.tensor(time_series, dtype=torch.float32)
        
        # ç”Ÿæˆé¢„æµ‹
        predictions = self.llm.generate(time_series)
        
        # å¦‚æžœæŒ‡å®šäº†è¾“å‡ºé•¿åº¦ï¼Œåˆ™æˆªå–
        if output_length and len(predictions) > output_length:
            predictions = predictions[:output_length]
        
        return predictions
    
    def batch_forecast(self, 
                      batch_series: list,
                      output_length: Optional[int] = None) -> list:
        """
        æ‰¹é‡æ—¶åºé¢„æµ‹
        
        Args:
            batch_series: æ‰¹é‡æ—¶åºæ•°æ®
            output_length: è¾“å‡ºé•¿åº¦
            
        Returns:
            æ‰¹é‡é¢„æµ‹ç»“æžœ
        """
        results = []
        for series in batch_series:
            pred = self.forecast(series, output_length)
            results.append(pred)
        return results
    
    def get_model_capabilities(self) -> Dict[str, Any]:
        """èŽ·å–æ¨¡åž‹èƒ½åŠ›ä¿¡æ¯"""
        return {
            "input_length": self.model_info["input_length"],
            "output_length": self.model_info["output_length"],
            "model_type": self.model_info["model_type"],
            "supported_tasks": ["time_series_forecasting"],
            "batch_inference": True,
            "streaming_inference": False
        }

# ä¾¿æ·å‡½æ•°
def create_timer_llm(cache_dir: Optional[str] = None, 
                    uri: Optional[str] = None) -> IoTDBLLM:
    """åˆ›å»ºTimerXLæ¨¡åž‹çš„IoTDB LLM"""
    return IoTDBLLM("timer", cache_dir=cache_dir, uri=uri)

def create_sundial_llm(cache_dir: Optional[str] = None,
                      uri: Optional[str] = None) -> IoTDBLLM:
    """åˆ›å»ºSundialæ¨¡åž‹çš„IoTDB LLM"""
    return IoTDBLLM("sundial", cache_dir=cache_dir, uri=uri)

def create_llm_from_uri(uri: str, 
                       cache_dir: Optional[str] = None) -> IoTDBLLM:
    """ä»ŽURIåˆ›å»ºIoTDB LLM"""
    return IoTDBLLM("custom", cache_dir=cache_dir, uri=uri)